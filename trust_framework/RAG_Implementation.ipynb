{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n",
      "üìÇ Working directory: /Users/anupamagaranisheshagiri/Documents/01ANUCOURSEWORK/PROJECTS/ULTIMATE RAG/trust_framework\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# PDF Processing\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Vector Store and Embeddings\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# LangChain Components\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama  # For local LLM option\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# OpenAI - Primary choice for embeddings and LLM\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Check for OpenAI API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è OPENAI_API_KEY not found in environment variables\")\n",
    "    print(\"Please set it using: export OPENAI_API_KEY='your-key-here'\")\n",
    "\n",
    "\n",
    "# OpenAI (optional - for better responses)\n",
    "try:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    import openai\n",
    "    OPENAI_AVAILABLE = True\n",
    "except:\n",
    "    OPENAI_AVAILABLE = False\n",
    "    print(\"OpenAI not available - will use Ollama for local inference\")\n",
    "\n",
    "# Display utilities\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import textwrap\n",
    "\n",
    "print(\"‚úÖ All imports successful\")\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key found\n",
      "‚úÖ Configuration and helpers loaded\n",
      "üìÅ Documents path: ../trust_framework/documents\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Helper Functions\n",
    "class RAGConfig:\n",
    "    \"\"\"Configuration for RAG system\"\"\"\n",
    "    # Paths\n",
    "    DOCS_PATH = \"../trust_framework/documents\"\n",
    "    VECTOR_DB_PATH = \"../trust_framework/vector_stores\"\n",
    "    \n",
    "    # OpenAI settings\n",
    "    EMBEDDING_MODEL = \"text-embedding-3-small\"  # OpenAI's latest embedding model\n",
    "    LLM_MODEL = \"gpt-4.1\"  # or \"gpt-4\" for better quality\n",
    "    \n",
    "    # Chunking settings\n",
    "    CHUNK_SIZE = 1000\n",
    "    CHUNK_OVERLAP = 200\n",
    "    \n",
    "    # Demo settings\n",
    "    TOP_K_RESULTS = 3\n",
    "\n",
    "# Set OpenAI API key if available\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load from .env file if exists\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    # Prompt for API key if not set\n",
    "    api_key = input(\"Please enter your OpenAI API key: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    print(\"‚úÖ API key set for this session\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key found\")\n",
    "\n",
    "def display_header(title: str, level: int = 1):\n",
    "    \"\"\"Display formatted header\"\"\"\n",
    "    header = \"#\" * level + \" \" + title\n",
    "    display(Markdown(header))\n",
    "    \n",
    "def display_results(results: Dict[str, Any], title: str = \"Results\"):\n",
    "    \"\"\"Display results in formatted way\"\"\"\n",
    "    display(Markdown(f\"### {title}\"))\n",
    "    if isinstance(results, dict):\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, list):\n",
    "                display(Markdown(f\"**{key}:**\"))\n",
    "                for item in value[:3]:  # Show first 3\n",
    "                    display(Markdown(f\"- {str(item)[:200]}...\"))\n",
    "            else:\n",
    "                display(Markdown(f\"**{key}:** {str(value)[:500]}\"))\n",
    "    else:\n",
    "        display(Markdown(str(results)))\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> Tuple[str, Dict[str, Any]]:\n",
    "    \"\"\"Extract text and metadata from PDF\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf = PdfReader(file)\n",
    "            text = \"\"\n",
    "            metadata = {\n",
    "                'filename': os.path.basename(pdf_path),\n",
    "                'num_pages': len(pdf.pages),\n",
    "                'file_size': os.path.getsize(pdf_path),\n",
    "                'document_type': 'unknown',  # Will be enriched later\n",
    "                'extracted_date': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            # Extract text from all pages\n",
    "            for page_num, page in enumerate(pdf.pages):\n",
    "                page_text = page.extract_text()\n",
    "                text += f\"\\n--- Page {page_num + 1} ---\\n{page_text}\"\n",
    "            \n",
    "            # Try to extract PDF metadata\n",
    "            if pdf.metadata:\n",
    "                metadata['pdf_metadata'] = {\n",
    "                    'title': pdf.metadata.get('/Title', 'N/A'),\n",
    "                    'author': pdf.metadata.get('/Author', 'N/A'),\n",
    "                    'subject': pdf.metadata.get('/Subject', 'N/A'),\n",
    "                    'creator': pdf.metadata.get('/Creator', 'N/A')\n",
    "                }\n",
    "            \n",
    "            return text, metadata\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "        return \"\", {}\n",
    "\n",
    "print(\"‚úÖ Configuration and helpers loaded\")\n",
    "print(f\"üìÅ Documents path: {RAGConfig.DOCS_PATH}\")\n",
    "# print(f\"ü§ñ Using {'Local LLM (Ollama)' if RAGConfig.USE_LOCAL_LLM else 'OpenAI'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'TESLA_Compensation_Table.pdf',\n",
       " 'num_pages': 50,\n",
       " 'file_size': 2109013,\n",
       " 'document_type': 'unknown',\n",
       " 'extracted_date': '2025-08-05T20:50:00.061738',\n",
       " 'pdf_metadata': {'title': 'DEF 14A',\n",
       "  'author': 'N/A',\n",
       "  'subject': 'N/A',\n",
       "  'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/138.0.0.0 Safari/537.36'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## üìö Loading Tesla Documents"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Processing: TESLA_SEC_8K_July_2025.pdf\n",
      "  ‚úì Pages: 1\n",
      "  ‚úì Type: unknown\n",
      "  ‚úì Size: 67,297 bytes\n",
      "\n",
      "üìÑ Processing: TESLA_SEC_10K.pdf\n",
      "  ‚úì Pages: 80\n",
      "  ‚úì Type: unknown\n",
      "  ‚úì Size: 1,143,548 bytes\n",
      "\n",
      "üìÑ Processing: TESLA_SEC_10Q_June_2025.pdf\n",
      "  ‚úì Pages: 32\n",
      "  ‚úì Type: unknown\n",
      "  ‚úì Size: 373,571 bytes\n",
      "\n",
      "üìÑ Processing: TESLA_SEC_8K_August_2025.pdf\n",
      "  ‚úì Pages: 1\n",
      "  ‚úì Type: unknown\n",
      "  ‚úì Size: 103,831 bytes\n",
      "\n",
      "üìÑ Processing: TESLA-Handbook.pdf\n",
      "  ‚úì Pages: 4\n",
      "  ‚úì Type: employee_handbook\n",
      "  ‚úì Size: 108,828 bytes\n",
      "\n",
      "üìÑ Processing: TESLA_Compensation_Table.pdf\n",
      "  ‚úì Pages: 50\n",
      "  ‚úì Type: unknown\n",
      "  ‚úì Size: 2,109,013 bytes\n",
      "\n",
      "‚úÖ Loaded 6 documents\n"
     ]
    }
   ],
   "source": [
    "# Load and Analyze Tesla Documents\n",
    "display_header(\"üìö Loading Tesla Documents\", 2)\n",
    "\n",
    "# Create paths if they don't exist\n",
    "os.makedirs(RAGConfig.DOCS_PATH, exist_ok=True)\n",
    "os.makedirs(RAGConfig.VECTOR_DB_PATH, exist_ok=True)\n",
    "\n",
    "# Load all PDFs\n",
    "documents_data = []\n",
    "pdf_files = list(Path(RAGConfig.DOCS_PATH).glob(\"*.pdf\"))\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"‚ö†Ô∏è No PDF files found. Please ensure Tesla documents are in:\", RAGConfig.DOCS_PATH)\n",
    "    print(\"Expected files:\")\n",
    "    print(\"  - Tesla 8-K 2025-07-23.pdf\")\n",
    "    print(\"  - Tesla 8-K 2025-08-03.pdf\")\n",
    "    print(\"  - Tesla 10-Q 2025-06-30.pdf\")\n",
    "    print(\"  - Tesla-Handbook.pdf\")\n",
    "else:\n",
    "    for pdf_path in pdf_files:\n",
    "        print(f\"\\nüìÑ Processing: {pdf_path.name}\")\n",
    "        text, metadata = extract_text_from_pdf(str(pdf_path))\n",
    "        \n",
    "        # Enrich metadata based on filename\n",
    "        if \"8-K\" in pdf_path.name:\n",
    "            metadata['document_type'] = 'earnings_announcement'\n",
    "            metadata['form_type'] = '8-K'\n",
    "            metadata['category'] = 'financial_news'\n",
    "        elif \"10-Q\" in pdf_path.name:\n",
    "            metadata['document_type'] = 'quarterly_report'\n",
    "            metadata['form_type'] = '10-Q'\n",
    "            metadata['category'] = 'financial_filing'\n",
    "        elif \"Handbook\" in pdf_path.name:\n",
    "            metadata['document_type'] = 'employee_handbook'\n",
    "            metadata['form_type'] = 'internal'\n",
    "            metadata['category'] = 'hr_policies'\n",
    "        \n",
    "        documents_data.append({\n",
    "            'text': text,\n",
    "            'metadata': metadata,\n",
    "            'path': str(pdf_path)\n",
    "        })\n",
    "        \n",
    "        print(f\"  ‚úì Pages: {metadata['num_pages']}\")\n",
    "        print(f\"  ‚úì Type: {metadata['document_type']}\")\n",
    "        print(f\"  ‚úì Size: {metadata['file_size']:,} bytes\")\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(documents_data)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## üßÆ Setting Up OpenAI Embeddings and Vector Store"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OpenAI embedding model...\n",
      "‚úÖ OpenAI Embedding model loaded (dimension: 1536)\n",
      "   Model: text-embedding-3-small\n",
      "‚úÖ Vector store initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Embedding Model and Vector Store\n",
    "display_header(\"üßÆ Setting Up OpenAI Embeddings and Vector Store\", 2)\n",
    "\n",
    "# Initialize OpenAI embedding model\n",
    "print(\"Loading OpenAI embedding model...\")\n",
    "try:\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=RAGConfig.EMBEDDING_MODEL,\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    # Test embedding\n",
    "    test_embedding = embeddings.embed_query(\"test\")\n",
    "    print(f\"‚úÖ OpenAI Embedding model loaded (dimension: {len(test_embedding)})\")\n",
    "    print(f\"   Model: {RAGConfig.EMBEDDING_MODEL}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading OpenAI embeddings: {e}\")\n",
    "    print(\"Please check your API key and try again\")\n",
    "    raise\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "chroma_client = chromadb.PersistentClient(path=RAGConfig.VECTOR_DB_PATH)\n",
    "\n",
    "# \n",
    "print(\"‚úÖ Vector store initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö® ZONE 1 : Strategy Failures (Index Everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üö® ZONE 1: STRATEGY FAILURES"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Problem: 'Index Everything' Approach"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FAILED approach: Indexing everything without strategy...\n",
      "\n",
      "‚ùå Created 965 chunks with minimal metadata\n",
      "\n",
      "üîç Test Query: 'What are Tesla's cybersecurity risks and data protection challenges?'\n",
      "\n",
      "‚ùå BAD RESULTS (No Strategy):\n",
      "\n",
      "1. Source: TESLA_Compensation_Table.pdf\n",
      "   Content: and practices with respect to data security risk exposures, and providing oversight over Tesla‚Äôs data\n",
      "security policies and monitoring programs. The Audit Committee receives regular updates from\n",
      "senior management, including our Chief Information Officer, on data security risk reviews of Tesla‚Äôs\n",
      "key business segments and products, procedures to assess and address data security risk, and the\n",
      "effectiveness of data security technologies and solutions deployed internally.\n",
      " \n",
      "Data Privacy\n",
      " \n",
      "Privacy is integral to our business and Tesla is committed to the protection of the personal data which\n",
      "it processes as part of its business and on behalf of customers. We have established a robust global\n",
      "privacy program with oversight by executive management, an independent Data Protection Officer\n",
      "for our European regulated entities, and, at the Board level, our Audit Committee. Our governance\n",
      "and accountability measures promote core principles of data privacy, while the collaborative effort...\n",
      "\n",
      "2. Source: TESLA_SEC_10K.pdf\n",
      "   Content: Union requiring certain data protection measures when handling, with a significant risk of fines for noncompliance. Similarly, our North American operations are subject to complex and changing federal and US state-specific data privacy laws and regulations, such as the California Consumer Privacy Act which imposes certain legal obligations on our use and processing of personal information related to California residents. Finally, additional\n",
      "privacy and cybersecurity laws have come into effect in China, and other jurisdictions where Tesla has a market presence.\n",
      "These laws continue to develop and may be inconsistent from jurisdiction to jurisdiction. Complying with emerging and changing requirements may cause us to incur substantial costs and make enhancements to relevant data practices. Noncompliance could result in significant penalties or legal liability.\n",
      "Table of Contents...\n",
      "\n",
      "3. Source: TESLA_Compensation_Table.pdf\n",
      "   Content: divestitures;\n",
      "‚Ä¢ Monitoring the integrity of Tesla‚Äôs financial statements and Tesla‚Äôs compliance with legal and\n",
      "regulatory requirements as they relate to financial statements or accounting matters; and\n",
      "‚Ä¢ Reviewing the adequacy and effectiveness of Tesla‚Äôs internal control policies and procedures in\n",
      "addition to Tesla‚Äôs risk management, data privacy and data security.\n",
      " \n",
      "In addition to overseeing key risks in the areas of data security and privacy, crisis risk management,\n",
      "ethics and compliance, and ESG, as discussed below, the Audit Committee is also responsible for\n",
      "overseeing risks in other areas of our business and operation.\n",
      " \n",
      "Additional Key Objectives\n",
      " \n",
      "Data Security\n",
      " \n",
      "The Audit Committee is responsible for reviewing the adequacy and effectiveness of Tesla‚Äôs policies\n",
      "and practices with respect to data security risk exposures, and providing oversight over Tesla‚Äôs data\n",
      "security policies and monitoring programs. The Audit Committee receives regular updates from...\n",
      "\n",
      "‚ö†Ô∏è PROBLEM: Getting employee handbook IT policies instead of actual risk assessments!\n"
     ]
    }
   ],
   "source": [
    "#  Zone 1 - Strategy Failures (Index Everything)\n",
    "display_header(\"üö® ZONE 1: STRATEGY FAILURES\", 1)\n",
    "display_header(\"Problem: 'Index Everything' Approach\", 2)\n",
    "\n",
    "print(\"Creating FAILED approach: Indexing everything without strategy...\\n\")\n",
    "\n",
    "# BAD APPROACH: Just dump everything into vector store\n",
    "bad_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=RAGConfig.CHUNK_SIZE,\n",
    "    chunk_overlap=RAGConfig.CHUNK_OVERLAP,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# Create documents without any filtering or strategy\n",
    "bad_documents = []\n",
    "for doc_data in documents_data:\n",
    "    chunks = bad_text_splitter.split_text(doc_data['text'])\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        bad_documents.append(Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                'source': doc_data['metadata']['filename'],\n",
    "                'chunk_id': i\n",
    "                # Notice: No document type, no categorization!\n",
    "            }\n",
    "        ))\n",
    "\n",
    "print(f\"‚ùå Created {len(bad_documents)} chunks with minimal metadata\")\n",
    "\n",
    "# Create bad vector store\n",
    "try:\n",
    "    chroma_client.delete_collection(\"bad_strategy\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "bad_vectorstore = Chroma.from_documents(\n",
    "    documents=bad_documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"bad_strategy\",\n",
    "    client=chroma_client\n",
    ")\n",
    "\n",
    "# TEST: Query for cybersecurity risks\n",
    "test_query = \"What are Tesla's cybersecurity risks and data protection challenges?\"\n",
    "print(f\"\\nüîç Test Query: '{test_query}'\")\n",
    "\n",
    "bad_results = bad_vectorstore.similarity_search(test_query, k=3)\n",
    "print(\"\\n‚ùå BAD RESULTS (No Strategy):\")\n",
    "for i, doc in enumerate(bad_results, 1):\n",
    "    print(f\"\\n{i}. Source: {doc.metadata['source']}\")\n",
    "    print(f\"   Content: {doc.page_content[:10000]}...\")\n",
    "    \n",
    "print(\"\\n‚ö†Ô∏è PROBLEM: Getting employee handbook IT policies instead of actual risk assessments!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## ‚úÖ ZONE 1 FIX: Strategic Document Selection"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating GOOD approach: Strategic indexing for risk analysis use case...\n",
      "\n",
      "‚úÖ Created 236 strategic chunks (risk-focused)\n",
      "   Reduction: 965 ‚Üí 236 chunks\n",
      "\n",
      "‚úÖ GOOD RESULTS (Strategic Indexing):\n",
      "\n",
      "1. Source: TESLA_SEC_10K.pdf (unknown)\n",
      "   Content: Union requiring certain data protection measures when handling, with a significant risk of fines for noncompliance. Similarly, our North American operations are subject to complex and changing federal and US state-specific data privacy laws and regulations, such as the California Consumer Privacy Act which imposes certain legal obligations on our use and processing of personal information related to California residents. Finally, additional\n",
      "privacy and cybersecurity laws have come into effect in China, and other jurisdictions where Tesla has a market presence.\n",
      "These laws continue to develop and may be inconsistent from jurisdiction to jurisdiction. Complying with emerging and changing requirements may cause us to incur substantial costs and make enhancements to relevant data practices. Noncompliance could result in significant penalties or legal liability.\n",
      "Table of Contents...\n",
      "\n",
      "2. Source: TESLA_SEC_10K.pdf (unknown)\n",
      "   Content: We are also subject to various other legal proceedings, risks and claims that arise from the normal course of business activities. For example, during the second quarter of 2023, a foreign news outlet reported that it obtained certain misappropriated data including, purportedly non-public Tesla business and personal information. Tesla has made notifications to potentially affected individuals (current and former employees) and regulatory\n",
      "authorities and we are working with certain law enforcement and other authorities. On August 5, 2023, a putative class action was filed in the United States District Court for the Northern District of California, purportedly on behalf of all U.S. individuals impacted by the data incident, followed by several additional lawsuits, that each assert claims under various state laws and seeks monetary damages and other relief. If an unfavorable ruling...\n",
      "\n",
      "3. Source: TESLA_SEC_10K.pdf (unknown)\n",
      "   Content: Table of Contents\n",
      "We are highly dependent on the services of Elon Musk, Technoking of Tesla and our Chief Executive Officer.\n",
      "We are highly dependent on the services of Elon Musk, Technoking of Tesla and our Chief Executive Officer. Although Mr. Musk spends significant time with Tesla and is highly active in our management, he does not devote his full time and attention to Tesla. For example: Mr. Musk also currently holds management positions at Space Exploration Technologies Corp., X Corp., X.AI Corp., Neuralink Corp. and The Boring Company,\n",
      "and is involved in other ventures and with the Department of Government Efficiency.\n",
      "Our information technology systems or data, or those of our service providers or customers or users could be subject to cyber-attacks or other security incidents, which could result in data breaches, intellectual property theft, claims, litigation, regulatory investigations, significant liability, reputational damage and other adverse consequences....\n",
      "\n",
      "‚úÖ SUCCESS: Now getting actual risk assessments from 10-Q and 8-K filings!\n"
     ]
    }
   ],
   "source": [
    "display_header(\"‚úÖ ZONE 1 FIX: Strategic Document Selection\", 2)\n",
    "\n",
    "print(\"Creating GOOD approach: Strategic indexing for risk analysis use case...\\n\")\n",
    "\n",
    "# GOOD APPROACH: Strategic filtering for risk-related content\n",
    "def is_risk_relevant(text: str) -> bool:\n",
    "    \"\"\"Check if text chunk contains risk-related content\"\"\"\n",
    "    risk_keywords = [\n",
    "        'risk', 'uncertainty', 'challenge', 'threat', 'vulnerability',\n",
    "        'cybersecurity', 'data protection', 'compliance', 'regulation',\n",
    "        'liability', 'exposure', 'mitigation', 'factor', 'material'\n",
    "    ]\n",
    "    text_lower = text.lower()\n",
    "    return any(keyword in text_lower for keyword in risk_keywords)\n",
    "\n",
    "# Create strategic documents\n",
    "good_documents = []\n",
    "for doc_data in documents_data:\n",
    "    filename = doc_data['metadata'].get('filename', '').lower()\n",
    "    # Only index 10-K, 10-Q, 8-K for risk analysis\n",
    "    if any(code in filename for code in [\"10k\", \"10-q\", \"8k\"]):\n",
    "        chunks = bad_text_splitter.split_text(doc_data['text'])\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if is_risk_relevant(chunk):\n",
    "                good_documents.append(Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\n",
    "                        'source': doc_data['metadata'].get('filename', 'unknown'),\n",
    "                        'document_type': doc_data['metadata'].get('document_type', 'unknown'),\n",
    "                        'form_type': doc_data['metadata'].get('form_type', 'unknown'),\n",
    "                        'chunk_id': i,\n",
    "                        'is_risk_content': True\n",
    "                    }\n",
    "                ))\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Created {len(good_documents)} strategic chunks (risk-focused)\")\n",
    "# Optional: If you have 'bad_documents', show reduction; else, just print the new count.\n",
    "if 'bad_documents' in locals():\n",
    "    print(f\"   Reduction: {len(bad_documents)} ‚Üí {len(good_documents)} chunks\")\n",
    "else:\n",
    "    print(f\"   (Set reduction line once you define bad_documents earlier)\")\n",
    "\n",
    "# Create good vector store\n",
    "try:\n",
    "    chroma_client.delete_collection(\"good_strategy\")\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "good_vectorstore = Chroma.from_documents(\n",
    "    documents=good_documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"good_strategy\",\n",
    "    client=chroma_client\n",
    ")\n",
    "\n",
    "# TEST: Same query\n",
    "good_results = good_vectorstore.similarity_search(test_query, k=3)\n",
    "print(f\"\\n‚úÖ GOOD RESULTS (Strategic Indexing):\")\n",
    "for i, doc in enumerate(good_results, 1):\n",
    "    print(f\"\\n{i}. Source: {doc.metadata['source']} ({doc.metadata['document_type']})\")\n",
    "    print(f\"   Content: {doc.page_content[:10000]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ SUCCESS: Now getting actual risk assessments from 10-Q and 8-K filings!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö® ZONE 2 - Data Quality Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üö® ZONE 2: DATA QUALITY CRISIS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Problem: Poor Metadata and Document Classification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: 'What is Tesla‚Äôs revenue currently?'\n",
      "\n",
      "‚ùå BAD RESULTS (Poor Metadata):\n",
      "  - File: TESLA_Compensation_Table.pdf\n",
      "  - File: TESLA_SEC_10Q_June_2025.pdf\n",
      "  - File: TESLA_SEC_10Q_June_2025.pdf\n",
      "\n",
      "‚ö†Ô∏è PROBLEM: Can't distinguish between 8-K news and 10-Q detailed reports!\n",
      "\n",
      "ü§ñ LLM's (misleading) Answer with BAD METADATA:\n",
      "\n",
      "Based on the provided context, **Tesla‚Äôs current revenue for Q2 2025 is $22,496 million ($22.5 billion)**, as reported in the official SEC 10-Q filing (TESLA_SEC_10Q_June_2025.pdf):\n",
      "\n",
      "> **Total revenues: $22,496 million** for the three months ended June 30, 2025.\n",
      "\n",
      "### Additional Notes:\n",
      "- The **$10,000 million** figure from the \"TESLA_Compensation_Table.pdf\" is inconsistent with the SEC filing and appears to be incorrect or possibly a typographical error.\n",
      "- The **$25,000 million** figure from the Board‚Äôs internal memo is also inconsistent with the official SEC filing.\n",
      "- The **SEC 10-Q filing** is the authoritative, externally reported source and should be used for financial analysis.\n",
      "\n",
      "**Conclusion:**  \n",
      "**Tesla‚Äôs current (Q2 2025) revenue is $22,496 million ($22.5 billion), as per the official SEC 10-Q filing.**\n",
      "\n",
      "‚ö†Ô∏è This answer may mix sources, be vague, or hallucinate because the context pool is wrong!\n"
     ]
    }
   ],
   "source": [
    "# Zone 2 - Data Quality Crisis\n",
    "display_header(\"üö® ZONE 2: DATA QUALITY CRISIS\", 1)\n",
    "display_header(\"Problem: Poor Metadata and Document Classification\", 2)\n",
    "\n",
    "# BAD APPROACH: Poor metadata\n",
    "bad_metadata_docs = []\n",
    "for doc_data in documents_data:\n",
    "    chunks = bad_text_splitter.split_text(doc_data['text'])\n",
    "    for i, chunk in enumerate(chunks[:10]):  # Just first 10 for demo\n",
    "        bad_metadata_docs.append(Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                'file': doc_data['metadata']['filename'],  # Just filename, no context!\n",
    "                'id': i\n",
    "            }\n",
    "        ))\n",
    "\n",
    "\n",
    "fake_chunk_text = (\n",
    "    \"For Q2 2025, Tesla's revenue was $10,000 million (Ten Billion Dollars). \"\n",
    "    \"This amount is a new company record and reflects strong performance in all segments. \"\n",
    "    \"This is as per 10K SEC filing. Tesla‚Äôs Q2 2025 revenue was $25,000 million according to the Board‚Äôs internal memo\"\n",
    ")\n",
    "fake_chunk_metadata = {\n",
    "    \"file\": \"TESLA_Compensation_Table.pdf\",  # Make it look like a comp table\n",
    "    \"id\": 56  # Just a fake id\n",
    "}\n",
    "\n",
    "#### INJECTING FAKE REVENUE\n",
    "bad_metadata_docs.append(Document(\n",
    "    page_content=fake_chunk_text,\n",
    "    metadata=fake_chunk_metadata\n",
    "))\n",
    "\n",
    "\n",
    "try:\n",
    "    chroma_client.delete_collection(\"bad_metadata\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "bad_metadata_store = Chroma.from_documents(\n",
    "    documents=bad_metadata_docs,  # Subset for demo\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"bad_metadata\",\n",
    "    client=chroma_client\n",
    ")\n",
    "\n",
    "\n",
    "# Query for Q2 2025 compensation\n",
    "q2_query = \"What is Tesla‚Äôs revenue currently?\"\n",
    "print(f\"üîç Query: '{q2_query}'\")\n",
    "\n",
    "bad_meta_results = bad_metadata_store.similarity_search(q2_query, k=3)\n",
    "print(\"\\n‚ùå BAD RESULTS (Poor Metadata):\")\n",
    "for doc in bad_meta_results:\n",
    "    print(f\"  - File: {doc.metadata.get('file', 'unknown')}\")\n",
    "    # Can't filter by document type, might get wrong documents!\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è PROBLEM: Can't distinguish between 8-K news and 10-Q detailed reports!\")\n",
    "\n",
    "import openai\n",
    "\n",
    "# (Optional: For OpenAI v1 SDK, otherwise use langchain's LLM object if preferred)\n",
    "# Compose RAG-style context for the LLM\n",
    "rag_context = \"\\n\\n\".join([\n",
    "    f\"Source: {doc.metadata.get('file', 'unknown')}\\n{doc.page_content}\"\n",
    "    for doc in bad_meta_results\n",
    "])\n",
    "\n",
    "user_query = q2_query\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an expert financial analyst. Use the provided context to answer the user's question.\\n\"\n",
    ")\n",
    "\n",
    "llm_input = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Context:\\n{rag_context}\\n\\nQuestion: {user_query}\"}\n",
    "]\n",
    "\n",
    "# Send query to OpenAI (replace with your own LLM object if using LangChain)\n",
    "llm_response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1\",  # Or your LLM model\n",
    "    messages=llm_input,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"\\nü§ñ LLM's (misleading) Answer with BAD METADATA:\\n\")\n",
    "print(llm_response.choices[0].message.content)\n",
    "print(\"\\n‚ö†Ô∏è This answer may mix sources, be vague, or hallucinate because the context pool is wrong!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## ‚úÖ ZONE 2 FIX: Rich Metadata System"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: 'What is Tesla‚Äôs revenue currently?'\n",
      "\n",
      "‚úÖ GOOD RESULTS (Rich Metadata):\n",
      "\n",
      "üìÑ Document: TESLA_SEC_10Q_June_2025.pdf\n",
      "   Type: quarterly_report\n",
      "   Form: 10-Q\n",
      "   Content Type: financial_statement\n",
      "   Fiscal Period: N/A\n",
      "\n",
      "üìÑ Document: TESLA_SEC_10Q_June_2025.pdf\n",
      "   Type: quarterly_report\n",
      "   Form: 10-Q\n",
      "   Content Type: financial_statement\n",
      "   Fiscal Period: N/A\n",
      "\n",
      "üìÑ Document: TESLA_SEC_10Q_June_2025.pdf\n",
      "   Type: quarterly_report\n",
      "   Form: 10-Q\n",
      "   Content Type: financial_statement\n",
      "   Fiscal Period: N/A\n",
      "\n",
      "ü§ñ LLM's Answer with GOOD METADATA:\n",
      "\n",
      "For the three months ended June 30, 2025, Tesla‚Äôs revenue is $22,496 million. For the six months ended June 30, 2025, Tesla‚Äôs revenue is $41,831 million.\n",
      "\n",
      "‚úÖ This answer is sourced ONLY from the correct, authoritative document!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "display_header(\"‚úÖ ZONE 2 FIX: Rich Metadata System\", 2)\n",
    "\n",
    "def extract_rich_metadata(text: str, base_metadata: dict) -> dict:\n",
    "    \"\"\"Extract rich metadata from document content\"\"\"\n",
    "    metadata = base_metadata.copy()\n",
    "\n",
    "    # Tag document_type and category from filename (add this ONCE per doc for reliability)\n",
    "    filename = metadata.get('filename', '').lower()\n",
    "    if '10q' in filename:\n",
    "        metadata['document_type'] = 'quarterly_report'\n",
    "        metadata['category'] = 'financial_filing'\n",
    "        metadata['form_type'] = '10-Q'\n",
    "    elif '10k' in filename:\n",
    "        metadata['document_type'] = 'annual_report'\n",
    "        metadata['category'] = 'financial_filing'\n",
    "        metadata['form_type'] = '10-K'\n",
    "    elif '8k' in filename:\n",
    "        metadata['document_type'] = 'news_release'\n",
    "        metadata['category'] = 'financial_news'\n",
    "        metadata['form_type'] = '8-K'\n",
    "    elif 'handbook' in filename:\n",
    "        metadata['document_type'] = 'employee_handbook'\n",
    "        metadata['category'] = 'hr_policy'\n",
    "    elif 'compensation' in filename:\n",
    "        metadata['document_type'] = 'compensation_table'\n",
    "        metadata['category'] = 'governance'\n",
    "    else:\n",
    "        metadata['document_type'] = 'unknown'\n",
    "        metadata['category'] = 'other'\n",
    "\n",
    "    # --- Your enrichment logic below ---\n",
    "\n",
    "    # Extract date references\n",
    "    date_pattern = r'\\b(\\d{1,2}/\\d{1,2}/\\d{4}|\\w+ \\d{1,2}, \\d{4})\\b'\n",
    "    dates = re.findall(date_pattern, text[:1000])\n",
    "    if dates:\n",
    "        metadata['reference_dates'] = ', '.join(dates[:3])\n",
    "\n",
    "    # Extract fiscal period\n",
    "    if \"quarter\" in text.lower():\n",
    "        quarter_pattern = r'(first|second|third|fourth|Q1|Q2|Q3|Q4)\\s+quarter'\n",
    "        quarters = re.findall(quarter_pattern, text.lower())\n",
    "        if quarters:\n",
    "            metadata['fiscal_period'] = quarters[0]\n",
    "\n",
    "    # Detect content type\n",
    "    text_lower = text.lower()\n",
    "    if \"financial statement\" in text_lower:\n",
    "        metadata['content_type'] = 'financial_statement'\n",
    "    elif \"risk factor\" in text_lower:\n",
    "        metadata['content_type'] = 'risk_disclosure'\n",
    "    elif \"management discussion\" in text_lower or \"md&a\" in text_lower:\n",
    "        metadata['content_type'] = 'management_discussion'\n",
    "    elif \"employee\" in text_lower and \"policy\" in text_lower:\n",
    "        metadata['content_type'] = 'hr_policy'\n",
    "\n",
    "    # Add quality score based on content\n",
    "    metadata['quality_score'] = len(text) / 100  # Simple length-based score\n",
    "\n",
    "    # Only keep primitive types for Chroma!\n",
    "    metadata = {k: v for k, v in metadata.items() if isinstance(v, (str, int, float, bool, type(None)))}\n",
    "    return metadata\n",
    "\n",
    "# Build enriched docs\n",
    "rich_metadata_docs = []\n",
    "for doc_data in documents_data:\n",
    "    chunks = bad_text_splitter.split_text(doc_data['text'])\n",
    "    for i, chunk in enumerate(chunks[:20]):  # Subset for demo speed\n",
    "        rich_meta = extract_rich_metadata(chunk, doc_data['metadata'])\n",
    "        rich_meta.update({\n",
    "            'chunk_index': i,\n",
    "            'chunk_size': len(chunk),\n",
    "            'indexing_timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        # Again: primitives only!\n",
    "        rich_meta = {k: v for k, v in rich_meta.items() if isinstance(v, (str, int, float, bool, type(None)))}\n",
    "        rich_metadata_docs.append(Document(\n",
    "            page_content=chunk,\n",
    "            metadata=rich_meta\n",
    "        ))\n",
    "\n",
    "try:\n",
    "    chroma_client.delete_collection(\"rich_metadata\")\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "rich_metadata_store = Chroma.from_documents(\n",
    "    documents=rich_metadata_docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"rich_metadata\",\n",
    "    client=chroma_client\n",
    ")\n",
    "\n",
    "# --- Filter and call LLM on authoritative content only! ---\n",
    "\n",
    "print(f\"üîç Query: '{q2_query}'\")\n",
    "print(\"\\n‚úÖ GOOD RESULTS (Rich Metadata):\")\n",
    "\n",
    "rich_results = rich_metadata_store.similarity_search(\n",
    "    q2_query, \n",
    "    k=3,\n",
    "    filter={\"document_type\": \"quarterly_report\"}  # Only 10-Qs!\n",
    ")\n",
    "\n",
    "for doc in rich_results:\n",
    "    meta = doc.metadata\n",
    "    print(f\"\\nüìÑ Document: {meta.get('filename', 'unknown')}\")\n",
    "    print(f\"   Type: {meta.get('document_type', 'unknown')}\")\n",
    "    print(f\"   Form: {meta.get('form_type', 'unknown')}\")\n",
    "    print(f\"   Content Type: {meta.get('content_type', 'unknown')}\")\n",
    "    print(f\"   Fiscal Period: {meta.get('fiscal_period', 'N/A')}\")\n",
    "\n",
    "\n",
    "# OPTIONAL: Feed ONLY these chunks to OpenAI for RAG answer\n",
    "rag_context = \"\\n\\n\".join([doc.page_content for doc in rich_results])\n",
    "system_prompt = (\n",
    "    \"You are an expert financial analyst. Use ONLY the provided context to answer the user's question. \"\n",
    "    \"If the answer is not present in the context, say 'Insufficient data.'\"\n",
    ")\n",
    "llm_input = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Context:\\n{rag_context}\\n\\nQuestion: {q2_query}\"}\n",
    "]\n",
    "llm_response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=llm_input,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"\\nü§ñ LLM's Answer with GOOD METADATA:\\n\")\n",
    "print(llm_response.choices[0].message.content)\n",
    "print(\"\\n‚úÖ This answer is sourced ONLY from the correct, authoritative document!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö® ZONE 3 - Prompt Engineering Disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= üö® ZONE 3: PROMPT ENGINEERING DISASTERS =\n",
      "\n",
      "== Problem: Generic Prompts vs Role-Specific ==\n",
      "Initializing OpenAI LLM...\n",
      "‚úÖ Using OpenAI gpt-4.1\n",
      "\n",
      "==============================\n",
      "‚ùå BAD RESULT (Generic Prompt):\n",
      "==============================\n",
      "**Answer:**\n",
      "\n",
      "Based on the provided context, Tesla should address cyber risk through a comprehensive and proactive approach that includes the following key actions:\n",
      "\n",
      "1. **Risk Identification and Disclosure:**  \n",
      "   Tesla should continue to identify and assess cybersecurity threats and disclose any material risks or incidents in its public filings, such as the Annual Report on Form 10-K under the risk factors section. This transparency helps inform investors and stakeholders about potential impacts on business strategy, operations, and financial condition.\n",
      "\n",
      "2. **Robust Cybersecurity Governance:**  \n",
      "   Tesla should maintain strong cybersecurity governance, ensuring that policies, procedures, and controls are in place to protect its information technology systems and data, as well as those of its service providers, customers, and users. This includes regular reviews and updates to security protocols to address evolving threats.\n",
      "\n",
      "3. **Incident Response and Mitigation:**  \n",
      "   Tesla should have a well-defined incident response plan to quickly detect, respond to, and recover from cyber-attacks or security incidents. This plan should minimize the risk of data breaches, intellectual property theft, and other adverse consequences such as litigation, regulatory investigations, and reputational damage.\n",
      "\n",
      "4. **Continuous Improvement:**  \n",
      "   As stated in the context, Tesla aspires to \"do the right thing\" and is \"constantly looking for ways to do better.\" This means regularly evaluating and enhancing cybersecurity measures, learning from past incidents, and adopting best practices and new technologies to strengthen defenses.\n",
      "\n",
      "5. **Employee Training and Awareness:**  \n",
      "   Tesla should ensure that employees, especially those in critical roles, are trained to recognize and respond to cybersecurity threats. This includes regular security awareness programs and updates on emerging risks.\n",
      "\n",
      "6. **Collaboration with Service Providers and Partners:**  \n",
      "   Since risks can also arise from third parties, Tesla should work closely with its service providers, customers, and users to ensure they adhere to strong cybersecurity standards and practices.\n",
      "\n",
      "7. **Regulatory Compliance:**  \n",
      "   Tesla should stay informed about and comply with all relevant cybersecurity regulations and reporting requirements, both in the U.S. and internationally.\n",
      "\n",
      "By implementing these measures, Tesla can better manage and mitigate cyber risks, protect its assets and reputation, and maintain the trust of its stakeholders.\n",
      "\n",
      "==============================\n",
      "‚úÖ GOOD RESULT (Role-Specific Prompt):\n",
      "==============================\n",
      "**TESLA EXECUTIVE BRIEFING: STRUCTURED CYBER RISK ASSESSMENT**  \n",
      "*Prepared for: Tesla Board of Directors*  \n",
      "*Prepared by: Senior Risk Analyst*  \n",
      "*Date: [Insert Date]*\n",
      "\n",
      "---\n",
      "\n",
      "### 1. KEY RISKS IDENTIFIED\n",
      "\n",
      "| Risk Description                                                                                  | Severity |\n",
      "|---------------------------------------------------------------------------------------------------|----------|\n",
      "| A. Cyber-attacks on Tesla‚Äôs IT systems, service providers, or customer/user data                  | High     |\n",
      "| B. Data breaches leading to exposure of sensitive customer, employee, or proprietary information   | High     |\n",
      "| C. Intellectual property theft (e.g., vehicle software, AI algorithms, manufacturing processes)    | High     |\n",
      "| D. Regulatory investigations and litigation following a cybersecurity incident                     | Medium   |\n",
      "| E. Reputational damage resulting from publicized cyber incidents                                  | High     |\n",
      "| F. Dependency on key personnel (Elon Musk) for strategic cyber risk oversight                     | Medium   |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. BUSINESS IMPACT\n",
      "\n",
      "- **A. Cyber-attacks/Data Breaches:**  \n",
      "  - *Potential Impact:*  \n",
      "    - Direct financial loss (estimated $100M‚Äì$500M per major incident, based on industry benchmarks for large-scale breaches)\n",
      "    - Disruption to manufacturing and supply chain operations (potential production halts, delayed deliveries)\n",
      "    - Loss of customer trust and market share (potential 5‚Äì10% drop in share price post-incident)\n",
      "- **B. Intellectual Property Theft:**  \n",
      "  - *Potential Impact:*  \n",
      "    - Loss of competitive advantage (difficult to quantify, but could result in billions in lost future revenue)\n",
      "    - Increased risk of counterfeit products or technology leaks\n",
      "- **C. Regulatory/Litigation Exposure:**  \n",
      "  - *Potential Impact:*  \n",
      "    - Fines and penalties (GDPR, CCPA, SEC, etc.; up to 4% of global annual revenue for GDPR violations)\n",
      "    - Legal costs and settlements (potentially $10M‚Äì$100M per incident)\n",
      "- **D. Reputational Damage:**  \n",
      "  - *Potential Impact:*  \n",
      "    - Long-term brand erosion, customer attrition, and negative media coverage\n",
      "    - Increased cost of capital and insurance premiums\n",
      "\n",
      "---\n",
      "\n",
      "### 3. CURRENT MITIGATIONS\n",
      "\n",
      "- **Governance:**  \n",
      "  - Cybersecurity risk is disclosed in annual filings and is part of risk factor disclosures.\n",
      "  - Tesla states an aspiration to ‚Äúdo the right thing‚Äù and to ‚Äúconstantly look for ways to do better.‚Äù\n",
      "- **Transparency:**  \n",
      "  - Regular SEC filings and public disclosures.\n",
      "  - Information made available on investor relations website.\n",
      "- **Leadership Oversight:**  \n",
      "  - Elon Musk is highly active in management, though not exclusively focused on Tesla.\n",
      "\n",
      "*Note: The context does not specify technical controls, dedicated cybersecurity teams, or detailed incident response plans.*\n",
      "\n",
      "---\n",
      "\n",
      "### 4. RECOMMENDATIONS\n",
      "\n",
      "1. **Enhance Cybersecurity Governance:**\n",
      "   - Establish a dedicated Cybersecurity Committee at the Board level.\n",
      "   - Appoint a Chief Information Security Officer (CISO) with direct reporting to the Board.\n",
      "2. **Strengthen Technical Controls:**\n",
      "   - Implement advanced threat detection and response systems (e.g., SIEM, EDR).\n",
      "   - Conduct regular third-party penetration testing and vulnerability assessments.\n",
      "   - Enforce multi-factor authentication and least-privilege access across all systems.\n",
      "3. **Supply Chain & Vendor Risk Management:**\n",
      "   - Require cybersecurity standards and regular audits for all critical suppliers and service providers.\n",
      "4. **Incident Response & Crisis Management:**\n",
      "   - Develop and regularly test a comprehensive incident response plan.\n",
      "   - Establish clear communication protocols for internal and external stakeholders.\n",
      "5. **Employee Training & Awareness:**\n",
      "   - Launch mandatory cybersecurity awareness training for all employees, with specialized training for high-risk roles.\n",
      "6. **Key Person Risk Mitigation:**\n",
      "   - Develop succession and delegation plans to reduce dependency on any single executive for cyber risk oversight.\n",
      "7. **Regulatory Compliance:**\n",
      "   - Ensure ongoing compliance with global data protection and cybersecurity regulations (GDPR, CCPA, etc.).\n",
      "   - Monitor evolving regulatory landscape and adapt policies accordingly.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. CONFIDENCE LEVEL\n",
      "\n",
      "**Medium**\n",
      "\n",
      "- *Rationale:*  \n",
      "  - The assessment is based on public filings and general disclosures, with limited detail on specific technical controls or incident history.  \n",
      "  - Confidence would be increased with access to internal audit reports, technical security assessments, and incident logs.\n",
      "\n",
      "---\n",
      "\n",
      "**Summary:**  \n",
      "Tesla faces significant cyber risk exposure due to its high-profile brand, complex supply chain, and reliance on proprietary technology. While governance and transparency are in place at a high level, there is a need for more robust, formalized cybersecurity controls and oversight. Immediate action is recommended to strengthen technical defenses, governance structures, and incident response capabilities.\n",
      "\n",
      "---\n",
      "\n",
      "*Prepared by: [Your Name], Senior Risk Analyst*\n",
      "\n",
      "‚úÖ SUCCESS: Role-specific prompt produces actionable, structured output!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# \n",
    "display_header(\"üö® ZONE 3: PROMPT ENGINEERING DISASTERS\", 1)\n",
    "display_header(\"Problem: Generic Prompts vs Role-Specific\", 2)\n",
    "\n",
    "# --- Display header helpers (optional) ---\n",
    "def display_header(text, level=1):\n",
    "    print(f\"\\n{'='*level} {text} {'='*level}\")\n",
    "\n",
    "# --- Setup: load API key ---\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(\"Loaded key:\", openai_api_key)\n",
    "\n",
    "\n",
    "good_documents = []\n",
    "for doc_data in documents_data:\n",
    "    filename = doc_data['metadata'].get('filename', '').lower()\n",
    "    # Only index 10-K, 10-Q, 8-K for risk analysis\n",
    "    if any(code in filename for code in [\"10k\", \"10-q\", \"8k\", \"def14a\"]):\n",
    "        chunks = bad_text_splitter.split_text(doc_data['text'])\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if is_risk_relevant(chunk):\n",
    "                good_documents.append(Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\n",
    "                        'source': doc_data['metadata'].get('filename', 'unknown'),\n",
    "                        'document_type': doc_data['metadata'].get('document_type', 'unknown'),\n",
    "                        'form_type': doc_data['metadata'].get('form_type', 'unknown'),\n",
    "                        'chunk_id': i,\n",
    "                        'is_risk_content': True\n",
    "                    }\n",
    "                ))\n",
    "\n",
    "try:\n",
    "    chroma_client.delete_collection(\"good_strategy\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "good_vectorstore = Chroma.from_documents(\n",
    "    documents=good_documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"good_strategy\",\n",
    "    client=chroma_client\n",
    ")\n",
    "\n",
    "# --- Initialize OpenAI LLM ---\n",
    "print(\"Initializing OpenAI LLM...\")\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=RAGConfig.LLM_MODEL,\n",
    "        temperature=0,\n",
    "        openai_api_key=openai_api_key\n",
    "    )\n",
    "    print(f\"‚úÖ Using OpenAI {RAGConfig.LLM_MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing OpenAI LLM: {e}\")\n",
    "    llm = None\n",
    "\n",
    "# --- PROMPT ENGINEERING SECTION ---\n",
    "\n",
    "\n",
    "# BAD PROMPT: Generic\n",
    "bad_prompt_template = \"\"\"\n",
    "Answer the question based on the context.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# GOOD PROMPT: Role-specific for Risk Analyst\n",
    "good_prompt_template = \"\"\"\n",
    "You are a Senior Risk Analyst preparing an executive briefing for Tesla's Board of Directors.\n",
    "\n",
    "Your task is to analyze the provided context and deliver a structured risk assessment that includes:\n",
    "1. KEY RISKS IDENTIFIED: List specific risks with severity levels (High/Medium/Low)\n",
    "2. BUSINESS IMPACT: Quantify potential impact where possible\n",
    "3. CURRENT MITIGATIONS: What controls are mentioned\n",
    "4. RECOMMENDATIONS: Actionable steps for risk reduction\n",
    "5. CONFIDENCE LEVEL: Rate your confidence in this assessment (High/Medium/Low) based on data quality\n",
    "\n",
    "Context from Tesla filings:\n",
    "{context}\n",
    "\n",
    "Risk Analysis Question: {question}\n",
    "\n",
    "STRUCTURED RISK ASSESSMENT:\n",
    "\"\"\"\n",
    "\n",
    "# --- Create QA Chains ---\n",
    "if llm:\n",
    "    bad_qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=good_vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        chain_type_kwargs={\n",
    "            \"prompt\": PromptTemplate(\n",
    "                template=bad_prompt_template,\n",
    "                input_variables=[\"context\", \"question\"]\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    good_qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=good_vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        chain_type_kwargs={\n",
    "            \"prompt\": PromptTemplate(\n",
    "                template=good_prompt_template,\n",
    "                input_variables=[\"context\", \"question\"]\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "# --- Test Query ---\n",
    "risk_query = \"How should Tesla address cyber risk?\"\n",
    "\n",
    "print(f\"\\n{'='*30}\\n‚ùå BAD RESULT (Generic Prompt):\\n{'='*30}\")\n",
    "if llm:\n",
    "    bad_response = bad_qa_chain.run(risk_query)\n",
    "    print(bad_response)\n",
    "else:\n",
    "    print(\"Tesla has some cybersecurity risks related to data and systems. \"\n",
    "          \"The company faces challenges with protecting information. \"\n",
    "          \"There are various security measures in place.\")\n",
    "\n",
    "print(f\"\\n{'='*30}\\n‚úÖ GOOD RESULT (Role-Specific Prompt):\\n{'='*30}\")\n",
    "if llm:\n",
    "    good_response = good_qa_chain.run(risk_query)\n",
    "    print(good_response)\n",
    "else:\n",
    "    print(\"\"\"\n",
    "STRUCTURED RISK ASSESSMENT:\n",
    "\n",
    "1. KEY RISKS IDENTIFIED:\n",
    "   - Data Breach Risk: HIGH - Customer personal and vehicle data exposure\n",
    "   - Ransomware Attack: MEDIUM - Manufacturing systems vulnerability\n",
    "   - Supply Chain Compromise: HIGH - Third-party vendor security gaps\n",
    "\n",
    "2. BUSINESS IMPACT:\n",
    "   - Potential regulatory fines: $50M-$500M\n",
    "   - Brand reputation damage: 10-15% customer trust decline\n",
    "   - Operational disruption: 3-7 days production halt\n",
    "\n",
    "3. CURRENT MITIGATIONS:\n",
    "   - ISO 27001 certification in progress\n",
    "   - Quarterly security audits\n",
    "   - Employee security training program\n",
    "\n",
    "4. RECOMMENDATIONS:\n",
    "   - Implement zero-trust architecture by Q4 2025\n",
    "   - Enhance vendor security assessments\n",
    "   - Establish 24/7 SOC operations\n",
    "\n",
    "5. CONFIDENCE LEVEL: MEDIUM\n",
    "   Based on Q2 10-Q filing and recent 8-K disclosures\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ SUCCESS: Role-specific prompt produces actionable, structured output!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö® ZONE 4 - Evaluation Blind Spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= üö® ZONE 4: EVALUATION BLIND SPOTS =\n",
      "\n",
      "== Problem: No Citations or Source Tracking ==\n",
      "\n",
      "‚ùå BAD RESULT (No Citations, No Source):\n",
      "Tesla faces significant regulatory risks related to autonomous driving. In ECE markets, specific regulations can restrict or prevent the use of advanced driver-assistance or self-driving features, impacting vehicle design and functionality. Other countries, such as China, are still developing their own regulations, which may differ significantly from those in the U.S. and ECE markets, adding further legal complexity and potentially limiting or prohibiting certain features.\n",
      "\n",
      "In the U.S., there are no federal regulations specifically for self-driving vehicles, but the NHTSA has issued guidelines and retains authority over vehicle safety and compliance. Additionally, individual states have their own laws regarding the operation, registration, and licensing of self-driving vehicles, creating a patchwork of regulations that complicates Tesla‚Äôs ability to design, sell, and operate autonomous vehicles nationwide.\n",
      "\n",
      "This evolving and inconsistent regulatory environment can delay, restrict, or prohibit the introduction of certain self-driving functionalities and vehicle designs. It also increases the risk of conflicting requirements, enforcement actions, or changes in policy, all of which could negatively impact Tesla‚Äôs business related to Autopilot, FSD (Supervised), and future autonomous vehicles.\n",
      "‚ö†Ô∏è User can‚Äôt check sources or verify anything.\n",
      "\n",
      "‚úÖ GOOD RESULT (Full Citation System):\n",
      "Tesla faces significant regulatory risks regarding autonomous driving due to evolving and complex legal frameworks globally. In ECE markets, certain regulations restrict the design and use of advanced driver-assistance or self-driving features, potentially compromising or preventing their deployment. Other current and proposed laws may further hinder or complicate the introduction of self-driving vehicles in these regions. Additionally, key markets like China are still developing their own regulations, which may differ significantly from those in the U.S. and ECE markets, increasing legal complexity and potentially limiting or preventing certain features [1].\n",
      "\n",
      "In the U.S., there are currently no federal regulations specifically for self-driving vehicles, but the NHTSA has issued recommended guidelines and retains authority over vehicle safety and compliance. Various U.S. states have their own legal restrictions on the operation, registration, or licensure of self-driving vehicles, and many others are considering such laws. This creates a patchwork of regulations, increasing legal complexity for Tesla [2].\n",
      "\n",
      "These regulatory uncertainties and differences may adversely affect the design, performance, sale, marketing, registration, and operation of Tesla‚Äôs Autopilot, FSD (Supervised), and future autonomous vehicles. Existing vehicle standards, not originally intended for vehicles without human drivers, may also pose challenges. The rapid changes and potential conflicts in regulations could delay, restrict, or prohibit certain functionalities and vehicle designs, negatively impacting Tesla‚Äôs business [3].\n",
      "\n",
      "Citations:\n",
      "[1]: TESLA_SEC_10K.pdf\n",
      "[2]: TESLA_SEC_10K.pdf\n",
      "[3]: TESLA_SEC_10K.pdf\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Zone 4 - Evaluation Blind Spots\n",
    "display_header(\"üö® ZONE 4: EVALUATION BLIND SPOTS\", 1)\n",
    "display_header(\"Problem: No Citations or Source Tracking\", 2)\n",
    "\n",
    "\n",
    "# BAD APPROACH: No citation tracking\n",
    "def bad_retrieval(query: str, vectorstore):\n",
    "    \"\"\"Retrieval without proper citation tracking\"\"\"\n",
    "    docs = vectorstore.similarity_search(query, k=3)\n",
    "    # Just concatenate text, lose all source info\n",
    "    combined_text = \" \".join([doc.page_content for doc in docs])\n",
    "    return {\n",
    "        'answer': f\"Based on the documents: {combined_text[:1000]}...\",\n",
    "        'sources': None  # No tracking!\n",
    "    }\n",
    "\n",
    "def bad_rag_llm_answer(query, vectorstore):\n",
    "    docs = vectorstore.similarity_search(query, k=3)\n",
    "    combined_context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    prompt = (\n",
    "        \"Answer the following question based ONLY on the provided context. \"\n",
    "        \"Do NOT cite any sources.\\n\\n\"\n",
    "        f\"Context:\\n{combined_context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    )\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def good_rag_llm_with_citations(query, vectorstore):\n",
    "    docs_with_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "    citations = []\n",
    "    context_with_refs = []\n",
    "    for i, (doc, score) in enumerate(docs_with_scores):\n",
    "        ref = f\"[{i+1}]\"\n",
    "        citations.append({\n",
    "            'citation_id': ref,\n",
    "            'source_document': doc.metadata.get('source', 'Unknown'),\n",
    "            'document_type': doc.metadata.get('document_type', 'Unknown'),\n",
    "            'relevance_score': float(1 / (1 + score)),\n",
    "            'excerpt': doc.page_content[:300] + \"...\"\n",
    "        })\n",
    "        context_with_refs.append(f\"{ref} {doc.page_content}\")\n",
    "    combined_context = \"\\n\\n\".join(context_with_refs)\n",
    "    prompt = (\n",
    "        \"Answer the following question based ONLY on the provided context. \"\n",
    "        \"Use inline citations [1], [2], etc., to indicate the source. If the answer is not present, say so.Format the answer\\n\\n\"\n",
    "        f\"Context:\\n{combined_context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    )\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content, citations\n",
    "\n",
    "\n",
    "# GOOD APPROACH: Full citation system\n",
    "def good_retrieval_with_citations(query: str, vectorstore):\n",
    "    \"\"\"Retrieval with complete citation tracking\"\"\"\n",
    "    # Get documents with scores\n",
    "    docs_with_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "    \n",
    "    citations = []\n",
    "    source_texts = []\n",
    "    \n",
    "    for i, (doc, score) in enumerate(docs_with_scores):\n",
    "        # Create detailed citation\n",
    "        citation = {\n",
    "            'citation_id': f\"[{i+1}]\",\n",
    "            'source_document': doc.metadata.get('source', 'Unknown'),\n",
    "            'document_type': doc.metadata.get('document_type', 'Unknown'),\n",
    "            'page_or_chunk': doc.metadata.get('chunk_id', 'Unknown'),\n",
    "            'relevance_score': float(1 / (1 + score)),  # Convert distance to similarity\n",
    "            'confidence': 'HIGH' if score < 0.5 else 'MEDIUM' if score < 1.0 else 'LOW',\n",
    "            'excerpt': doc.page_content[:1000] + \"...\"\n",
    "        }\n",
    "        citations.append(citation)\n",
    "        source_texts.append(f\"{citation['citation_id']} {doc.page_content}\")\n",
    "    \n",
    "    # Create response with inline citations\n",
    "    response = {\n",
    "        'query': query,\n",
    "        'answer': f\"Based on analysis of Tesla filings {citations[0]['citation_id']}, \"\n",
    "                  f\"the following risks were identified...\",\n",
    "        'citations': citations,\n",
    "        'source_documents': [c['source_document'] for c in citations],\n",
    "        'confidence_level': citations[0]['confidence'] if citations else 'LOW',\n",
    "        'retrieval_timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test both approaches\n",
    "test_query = \"Tesla autonomous driving regulatory risks\"\n",
    "\n",
    "print(\"\\n‚ùå BAD RESULT (No Citations, No Source):\")\n",
    "bad_llm_ans = bad_rag_llm_answer(test_query, good_vectorstore)\n",
    "print(bad_llm_ans)\n",
    "print(\"‚ö†Ô∏è User can‚Äôt check sources or verify anything.\")\n",
    "\n",
    "print(\"\\n\\n\\n‚úÖ GOOD RESULT (Full Citation System):\")\n",
    "good_llm_ans, citations = good_rag_llm_with_citations(test_query, good_vectorstore)\n",
    "print(good_llm_ans)\n",
    "print(\"\\nCitations:\")\n",
    "for citation in citations:\n",
    "    print(f\"{citation['citation_id']}: {citation['source_document']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö® ZONE 5 - Governance Catastrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_data in documents_data:\n",
    "    filename = doc_data['metadata'].get('filename', '').lower()\n",
    "    # TAG document_type and category based on filename\n",
    "    if \"10k\" in filename:\n",
    "        doc_data['metadata']['document_type'] = \"annual_report\"\n",
    "        doc_data['metadata']['category'] = \"financial_filing\"\n",
    "        doc_data['metadata']['form_type'] = \"10-K\"\n",
    "    elif \"10q\" in filename:\n",
    "        doc_data['metadata']['document_type'] = \"quarterly_report\"\n",
    "        doc_data['metadata']['category'] = \"financial_filing\"\n",
    "        doc_data['metadata']['form_type'] = \"10-Q\"\n",
    "    elif \"8k\" in filename:\n",
    "        doc_data['metadata']['document_type'] = \"earnings_announcement\"\n",
    "        doc_data['metadata']['category'] = \"financial_news\"\n",
    "        doc_data['metadata']['form_type'] = \"8-K\"\n",
    "    elif \"compensation\" in filename or \"table\" in filename:\n",
    "        doc_data['metadata']['document_type'] = \"compensation_table\"\n",
    "        doc_data['metadata']['category'] = \"governance\"\n",
    "        doc_data['metadata']['form_type'] = \"DEF 14A\"\n",
    "    elif \"handbook\" in filename:\n",
    "        doc_data['metadata']['document_type'] = \"employee_handbook\"\n",
    "        doc_data['metadata']['category'] = \"hr_policies\"\n",
    "        doc_data['metadata']['form_type'] = \"Handbook\"\n",
    "    else:\n",
    "        doc_data['metadata']['document_type'] = \"unknown\"\n",
    "        doc_data['metadata']['category'] = \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "all_documents = []\n",
    "for doc_data in documents_data:\n",
    "    chunks = bad_text_splitter.split_text(doc_data['text'])\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        all_documents.append(Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                'source': doc_data['metadata'].get('filename', 'unknown'),\n",
    "                'document_type': doc_data['metadata'].get('document_type', 'unknown'),\n",
    "                'category': doc_data['metadata'].get('category', 'unknown'),\n",
    "                'chunk_id': i\n",
    "            }\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chroma_client.delete_collection(\"good_vectorstore\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "good_vectorstore = Chroma.from_documents(\n",
    "    documents=all_documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"good_vectorstore\",   # name it as you like\n",
    "    client=chroma_client\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= üö® ZONE 5: GOVERNANCE CATASTROPHE =\n",
      "\n",
      "== Problem: No Access Controls ==\n",
      "SCENARIO 1: Junior Analyst tries to access compensation data\n",
      "üö´ ACCESS DENIED: 'compensation' in query for john_doe (junior_analyst)\n",
      "Insufficient data.\n",
      "\n",
      "SCENARIO 2: Senior Analyst accesses risk data\n",
      "üìù Audit: jane_smith (senior_analyst) accessed 5 docs.\n",
      "Cybersecurity Risks:\n",
      "The document notes that Tesla is subject to various legal proceedings, risks, and claims arising from normal business activities. Specifically, it references an incident in the second quarter of 2023, where a foreign news outlet reported obtaining misappropriated data, including purportedly non-public Tesla business information. This highlights the risk of data breaches and unauthorized access to sensitive information.\n",
      "\n",
      "Mitigation Strategies:\n",
      "The provided context does not specify particular mitigation strategies that Tesla employs to address cybersecurity risks.\n",
      "\n",
      "Summary:\n",
      "- Tesla faces cybersecurity risks, including data breaches and unauthorized disclosure of non-public business information.\n",
      "- Insufficient data on specific mitigation strategies from the provided context.\n",
      "\n",
      "SCENARIO 3: CEO accesses compensation data\n",
      "üìù Audit: ceo_user (executive) accessed 10 docs.\n",
      "Based on the provided context:\n",
      "\n",
      "Executive Compensation and Bonus Structure:\n",
      "- The Compensation Committee is responsible for reviewing and adjusting the base salaries of the Chief Executive Officer and other executive officers. These adjustments are made to reflect individual roles, performance, and the competitive market.\n",
      "- Compensation determinations by the Compensation Committee are largely discretionary, except for the CEO, whose compensation is approved by the Board.\n",
      "- The total annual compensation for executive officers includes base salary or wages, performance-based commission payments, and equity awards based on their grant date fair values.\n",
      "- The compensation program emphasizes at-risk compensation, particularly in the form of equity awards (such as stock options), to align the interests of executives and directors with those of Tesla‚Äôs stockholders.\n",
      "- The outside director compensation program consists primarily of equity awards (stock options) and relatively modest cash retainers.\n",
      "- There is no specific mention of a structured cash bonus program for executive officers in the provided context.\n",
      "\n",
      "Andrew Baglino Salary:\n",
      "- In 2022, Andrew Baglino‚Äôs base salary was $300,000, with total compensation (including other compensation) amounting to $303,000.\n",
      "- In 2021, his base salary was $300,000.\n",
      "- In 2020, his base salary was $275,000.\n",
      "\n",
      "No additional bonus or equity awards for Andrew Baglino are specified for 2022 or 2021 in the provided context.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import openai\n",
    "\n",
    "display_header(\"üö® ZONE 5: GOVERNANCE CATASTROPHE\", 1)\n",
    "display_header(\"Problem: No Access Controls\", 2)\n",
    "\n",
    "# Define user roles and minimal access controls\n",
    "class UserRole:\n",
    "    JUNIOR_ANALYST = \"junior_analyst\"\n",
    "    SENIOR_ANALYST = \"senior_analyst\"\n",
    "    EXECUTIVE = \"executive\"\n",
    "\n",
    "# Only the CEO can see compensation!\n",
    "ACCESS_CONTROLS = {\n",
    "    UserRole.JUNIOR_ANALYST: {\n",
    "        'allowed_document_types': ['quarterly_report', 'earnings_announcement'],\n",
    "        'restricted_keywords': ['compensation', 'salary', 'bonus', 'equity'],\n",
    "        'max_results': 3\n",
    "    },\n",
    "    UserRole.SENIOR_ANALYST: {\n",
    "        'allowed_document_types': ['quarterly_report', 'earnings_announcement'],\n",
    "        'restricted_keywords': ['compensation', 'salary', 'bonus', 'equity'],\n",
    "        'max_results': 5\n",
    "    },\n",
    "    UserRole.EXECUTIVE: {\n",
    "        'allowed_document_types': ['compensation_table', 'quarterly_report', 'earnings_announcement'],\n",
    "        'restricted_keywords': [],\n",
    "        'max_results': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "def llm_rag_answer(context_docs, query):\n",
    "    rag_context = \"\\n\\n\".join([f\"{doc.metadata.get('source', 'Unknown')}\\n{doc.page_content[:300]}...\" for doc in context_docs])\n",
    "    system_prompt = (\n",
    "        \"You are an expert analyst. Use ONLY the provided document context to answer the user's question. \"\n",
    "        \"If the answer is not in the context, reply 'Insufficient data.'\"\n",
    "    )\n",
    "    llm_input = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Context:\\n{rag_context}\\n\\nQuestion: {query}\"}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=llm_input,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def governed_retrieval(query, user, role):\n",
    "    controls = ACCESS_CONTROLS[role]\n",
    "    # Block on restricted keywords\n",
    "    for kw in controls['restricted_keywords']:\n",
    "        if kw in query.lower():\n",
    "            print(f\"üö´ ACCESS DENIED: '{kw}' in query for {user} ({role})\")\n",
    "            return \"Insufficient data.\"\n",
    "    # Restrict by allowed document type\n",
    "    docs = []\n",
    "    for doc_type in controls['allowed_document_types']:\n",
    "        docs += good_vectorstore.similarity_search(\n",
    "            query,\n",
    "            k=controls['max_results'],\n",
    "            filter={\"document_type\": doc_type}\n",
    "        )\n",
    "    # Deduplicate\n",
    "    seen = set()\n",
    "    unique_docs = []\n",
    "    for doc in docs:\n",
    "        uid = doc.metadata.get('source', '') + str(doc.metadata.get('chunk_id', ''))\n",
    "        if uid not in seen:\n",
    "            unique_docs.append(doc)\n",
    "            seen.add(uid)\n",
    "    docs = unique_docs[:controls['max_results']]\n",
    "    # If nothing retrieved, or not CEO asking compensation, block\n",
    "    if not docs or ('compensation' in query.lower() and role != UserRole.EXECUTIVE):\n",
    "        print(f\"üìù Audit: {user} ({role}) was blocked or no docs found.\")\n",
    "        return \"Insufficient data.\"\n",
    "    # CEO gets a real answer\n",
    "    print(f\"üìù Audit: {user} ({role}) accessed {len(docs)} docs.\")\n",
    "    return llm_rag_answer(docs, query)\n",
    "\n",
    "# ==== DEMO SCENARIOS ====\n",
    "\n",
    "print(\"SCENARIO 1: Junior Analyst tries to access compensation data\")\n",
    "print(governed_retrieval(\"executive compensation and bonus structure\", \"john_doe\", UserRole.JUNIOR_ANALYST))\n",
    "\n",
    "print(\"\\nSCENARIO 2: Senior Analyst accesses risk data\")\n",
    "print(governed_retrieval(\"cybersecurity risks and mitigation strategies\", \"jane_smith\", UserRole.SENIOR_ANALYST))\n",
    "\n",
    "print(\"\\nSCENARIO 3: CEO accesses compensation data\")\n",
    "print(governed_retrieval(\"executive compensation and bonus structure AND Andrew Baglino SALARY\", \"ceo_user\", UserRole.EXECUTIVE))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ultimate_rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
